Name,Contact Email,Link,Stimtype,Unzipped?,Citation,Permission to list in the DB,Notes
Experimental field linguistics db list,,https://experimentalfieldlinguistics.wordpress.com/experimental-materials/stimulusdatabases/,ListOfLists,Yes,,,
MRC Psycholinguistic Database,,http://websites.psychology.uwa.edu.au/school/MRCDatabase/MDWilsonMRC.pdf,Words,,,,
Wordnets in the World,,http://globalwordnet.org/wordnets-in-the-world/,Wordnets,,,,
UCSD Center for Research in Language International Picture-Naming Project,,http://crl.ucsd.edu/experiments/ipnp/,Picture,,,,
ChildFreq,,http://childfreq.sumsar.net/,Transcriptions,,,,Transcriptions of interactions with children
,,http://www.uni-potsdam.de/prim/labs-experiments/resources-software-databases/online-databases.html,,,,,Original link defunct: http://www.uni-potsdam.de/prim/research/resources.html
Postdam Research Institute for Multilingualism db list,,https://experimentalfieldlinguistics.wordpress.com/links/websites-with-links-to-psycholinguistics-resources/,,,,,
imagenet,,http://www.image-net.org/,Picture,,,,
UCI Machine Learning Repository,,http://archive.ics.uci.edu/ml/datasets.html,Various,,,,
cogsci.nl stim sets,,https://www.cogsci.nl/stimulus-sets,ListOfLists,Yes,,,
Stimuli for Large Pupils Predict Goal-Driven Eye Movements,,https://github.com/smathot/materials_for_P0010.5,Picture,,,,
Amsterdam Library of Object Images,,http://aloi.science.uva.nl/,Picture,,,,Original link defunct: http://staff.science.uva.nl/~aloi/
Bank of Standardized Stimuli,mathieu.brodeur@douglas.mcgill.ca,http://sites.google.com/site/mathieubrodeur/Home/boss,Picture,,,,
U Bourgogne db,,http://leadserv.u-bourgogne.fr/bases/pictures/,Picture,,"P. Bonin*, R. Peereman**, N. Malardier*, A. M_ot*, & M. Chalard*; * Universit_ Blaise-Pascal/C.N.R.S, Clermont-Ferrand, France;  ** Universit_ de Bourgogne/C.N.R.S, Dijon, France",,"Pictures are often used as stimuli in studies on perception, language and memory. As performance on different sets of pictures is generally contrasted, stimulus selection requires the use of standardized material to match pictures along various variables. Unfortunately, the number of standardized pictures available for empirical research is rather limited. The aim of the present study is to provide French normative data for a new set of 299 black-and-white drawings. Closely following Alario and Ferrand (1999), the pictures have been standardized on six variables: name agreement, image agreement, conceptual familiarity, visual complexity, image variability and age of acquisition. Objective frequency measures are also provided for the most common names associated with the pictures. Comparative analyses between our results and norms obtained in other similar studies are reported. Finally, naming latencies corresponding to the set of pictures were also collected from French native speakers and correlational/multiple regression analyses were performed on naming latencies. This new set of standardized pictures available from the Internet should be of great use to researchers when selecting pictorial stimuli."
Cat Dataset,xtang@ie.cuhk.edu.hk,https://web.archive.org/web/20150703060412/http://137.189.35.203/WebUI/CatDatabase/catData.html,Picture,,,,Archived version; original link is now defunct
CIPR Still Images,,http://www.cipr.rpi.edu/resource/stills/,Picture,,,,
Dartmouth Database of Children's Faces,kad@umn.edu,http://www.faceblind.org/social_perception/K_Dalrymple/DDCF.html,Picture,,"Dalrymple, K.A.,_Gomez, J., & Duchaine, B. (2013). The Dartmouth Database of Children's Faces: Acquisition and validation of a new face stimulus set. PLoS ONE 8(11): e79131",,
An Ecological Alternative to Snodgrass & Vanderwart: 360 High Quality Colour Images with Norms for Seven Psycholinguistic Variables,prmontoro@psi.uned.es,http://dx.plos.org/10.1371/journal.pone.0037527,Picture,,"Moreno-Martinez FJ, Montoro PR (2012) An Ecological Alternative to Snodgrass & Vanderwart: 360 High Quality Colour Images with Norms for Seven Psycholinguistic Variables. PLoS ONE 7(5): e37527. doi:10.1371/journal.pone.0037527",,
Hartfield Image Test,,http://testbed.herts.ac.uk/HIT/hit_apply.asp,Picture,,"Adlington, R. L., Laws, K. R., & Gale, T. M. (2008). The Hatfield Image Test (HIT): a new picture test and norms for experimental and clinical use.¾Journal of Clinical and Experimental Neuropsychology,¾under review.",,
U of FL Media Core,,http://csea.phhp.ufl.edu/media.html,ListOfMaterials,Yes,,,
International Affective Picture System,,http://csea.phhp.ufl.edu/media.html,Picture,,"Lang, P.J., Bradley, M.M., & Cuthbert, B.N. (2008). International affective picture system (IAPS): Affective ratings of pictures and instruction manual. Technical Report A-8. University of Florida, Gainesville, FL.",,
International Affective Digital Sounds,,http://csea.phhp.ufl.edu/media.html,Sound,,"Bradley, M. M., & Lang, P. J. (1999). International affective digitized sounds (IADS): Stimuli, instruction manual and affective ratings (Tech. Rep. No. B-2). Gainesville, FL: The Center for Research in Psychophysiology, University of Florida",,
Affective Norms for English Words,,http://csea.phhp.ufl.edu/media.html,Words,,"Bradley, M.M., & Lang, P.J. (1999). Affective norms for English words (ANEW): Stimuli, instruction manual and affective ratings. Technical report C-1, Gainesville, FL. The Center for Research in Psychophysiology, University of Florida.",,
Affective Norms for English Text,,http://csea.phhp.ufl.edu/media.html,Texts,,"Bradley, M. M., & Lang, P. J. (2007). Affective Norms for English Text (ANET): Affective ratings of text and instruction manual. (Tech. Rep. No. D-1). University of Florida, Gainesville, FL.",,
Self-Assessment Manikin,,http://csea.phhp.ufl.edu/media.html,Picture,,"Bradley, M. M., & Lang, P. J. (1994). Measuring emotion: The selff-assessment manikin and the semantic differential.¾Journal of Behavioral Therapy and Experimental Psychiatry, 25, 49-59.",,
Tarrlab Face Place db,,http://wiki.cnbc.cmu.edu/Face_Place,Faces,,"Stimulus images courtesy of Michael J. Tarr, Center for the Neural Basis of Cognition and Department of Psychology, Carnegie Mellon University,¾http://www.tarrlab.org/. Funding provided by NSF award 0339122.",,
FaceScrub,,http://vintage.winklerbros.net/facescrub.html,Faces,,"H.-W. Ng, S. Winkler. A data-driven approach to cleaning large face datasets. Proc. IEEE International Conference on Image Processing (ICIP), Paris, France, Oct. 27-30, 2014.",,
Leuven Embedded Figures Test Target Shapes,,https://doi.org/10.6084/m9.figshare.3807885,Shape,,"de-Wit, Lee; Huygelier, Hanne; Chamberlain, Rebecca; Van der Hallen, Ruth; Wagemans, Johan (2016): Leuven Embedded Figures Test Target Shapes. figshare.",,
Leuven Embedded Figures Test Context Shapes,,https://doi.org/10.6084/m9.figshare.3807894,Shape,,"de-Wit, Lee; Huygelier, Hanne; Chamberlain, Rebecca; Van der Hallen, Ruth; Wagemans, Johan (2016): Leuven Embedded Figures Test Context Shapes. figshare.",,
A visual object stimulus database with standardized similarity information,Ellen.Migo@kcl.ac.uk,http://link.springer.com/article/10.3758/s13428-012-0255-4/fulltext.html,Picture,,"Migo, E.M., Montaldi, D. & Mayes, A.R. Behav Res (2013) 45: 344. doi:10.3758/s13428-012-0255-4",,
UT Austin Natural Scene Statistics in Vision Science,w.geisler@utexas.edu¾,http://www.cps.utexas.edu/natural_scenes/,ListOfMaterials,,,,
Nature Scene Collection,w.geisler@utexas.edu¾,http://natural-scenes.cps.utexas.edu/db.shtml#nature_scene_collection,Picture,,"Geisler WS & Perry JS (2011). Statistics for optimal point prediction in natural images. Journal of Vision. October 19, 2011 vol. 11 no. 12 article 14.",,
Campus Scene Collection,jburge@sas.upenn.edu¾,http://natural-scenes.cps.utexas.edu/db.shtml#campus_scene_collection,Picture,,"Burge J, Geisler WS (2011). Optimal defocus estimation in individual natural images. Proceedings of the National Academy of Sciences, 108 (40): 16849-16854",,
Contour Database,w.geisler@utexas.edu¾,http://natural-scenes.cps.utexas.edu/db.shtml#kodakdb,Picture,,"WS Geisler, JS Perry, BJ Super, DP Gallogly (2001). Vision Research 41, 711-724.",,
Nencki Affective Picture System,,http://naps.nencki.gov.pl/,Picture,,"Marchewka A., _urawski _., Jednor„g K., Grabowska A. (2014)¾The Nencki Affective Picture System (NAPS): introduction to a novel, standardized, wide-range, high-quality, realistic picture database.¾Behavior Research Methods, 46(2), 596_610. doi:10.3758/s13428-013-0379-1.¾",,
The role of imagery-related properties in picture naming: A newly standardized set of 360 pictures for Japanese,nishi@waseda.jp,http://www.springerlink.com/content/5v773074154063rt/13428_2011_Article_176_ESM.html,Picture,,"Nishimoto, T., Ueda, T., Miyawaki, K. et al. Behav Res (2012) 44: 934. doi:10.3758/s13428-011-0176-7",,
Normative-ratings experiment for flanker stimuli,,http://dx.doi.org/10.6084/m9.figshare.977864,Shape,,"Chanceaux, Myriam; Math»t, Sebastiaan; Jonathan Grainger (2014): Normative-ratings experiment for flanker stimuli. figshare.",,
Novel Object & Unusual Name Database,mhout@nmsu.edu,http://michaelhout.com/?page_id=759,Object,,"Horst, J. S., & Hout, M. C. æ(in press). æThe Novel Object and Unusual Name (NOUN) Database: A collection of novel images for use in experimental research. æBehavior Research Methods.",,
,,http://www.oszillab.net/downloads.php,,,,,Defunct
Psychological Image Collection at Stirling,,http://pics.psych.stir.ac.uk/,Picture (mostly faces),,pics.stir.ac.uk.,,
CNBC Wiki,dpane@cnbc.cmu.edu,http://wiki.cnbc.cmu.edu/Objects,Object,,,,
Segmentation evaluation database,,http://www.wisdom.weizmann.ac.il/~vision/Seg_Evaluation_DB,Object,,"Sharon Alpert and Meirav Galun and Ronen Basri and Achi Brandt. Image Segmentation by Probabilistic Bottom-Up Aggregation and Cue Integration. Proceedings of the IEEE Conference on Computer Vision and PatternæRecognition, June 2007",,
,,http://www.cse.buffalo.edu/~yunfu/research/Kinface/Kinface.htm,,,,,Defunct
UPenn Natural Image Database,,http://tofu.psych.upenn.edu/~upennidb/,Scene,,"Tkacik G et al, ""Natural images from the birthplace of the human eye"", PLoS ONE 6: e20409 (2011).",,
VIU saliency,,https://labs.psych.ucsb.edu/eckstein/miguel/research_pages/saliencydata.html,Picture,,"ÊKoehler, K., Guo, F., Zhang, S., & Eckstein, M. P. (2014). What do saliency models predict? Journal of Vision, 14(3):14, 1Ð 27, http://www.journalofvision.org/content/14/3/14, doi:10.1167/14.3.14.",,
Brussels Artificial Character Sets,,https://osf.io/dj8qm/,Artificial characters,,"Vidal, C., Chetail, F., & Content, A. (2016, December 30). BACS: The Brussels Artificial Characters Sets for studies in cognitive psychology and neuroscience.Ê",,"Written symbols such as letters have been extensively used in cognitive psychology, be it to understand their contribution to written word recognition or to examine processes involved in other mental functions. Sometimes, however, researchers want to manipulate letters while removing their associated characteristics. A powerful solution to do so is to use new characters, devised to be highly similar to letters, but without associated sound or name. Given the growing use of artificial characters in experimental paradigms, the aim of the present study was to make available the Brussels Artificial Character Sets (BACS), two full, strictly controlled, and portable sets of artificial characters for a broad range of experimental situations."
FAMED face database,chris.longmore@plymouth.ac.uk,http://www.chrislongmore.co.uk/famed/index.html,Videos of faces,,"Longmore, C. A., & Tree, J. J. (2013). Motion as a cue to face recognition: Evidence from congenital prosopagnosia.ÊNeuropsychologia,Ê51, 864-875",,"TheÊFaces and Motion Exeter DatabaseÊ(FAMED) is a video database of 32 male actors for use in psychological research. ÊEach actor was filmed from two viewpoints (full-face and three-quarter) whilst they performed a series of facial motions including the telling of three jokes, a short conversation, six facial expressions (smiling, anger, fear, disgust, surprise and sadness) and rigid motion such as head rotation from left to right and up and down. ÊThe actors performed all actions three times; once with no headgear, once wearing a swimming cap to hide hair cues and once whilst wearing a wig."
Tarr Lab stimuli,,http://wiki.cnbc.cmu.edu/TarrLab,ListOfLists,No,,,
ViperLib,,https://www.merlot.org/merlot/viewMaterial.htm?id=86605,Picture,,,,Viperlib is a web-based resource library of images and presentation material illuminating the study of visual perception.
,,,,,,,
Psychonomics Society database,,,,,,,Super defunct
Swiss Center for Affective Sciences,,http://www.affective-sciences.org/en/home/research/materials-and-online-research/research-material/,ListOfMaterials,In progress,,,
,,http://www.cla.auburn.edu/psychology/assets/File/Goodman-Katz-Dretsch-JPTEP-2016.pdf,,,,,
EU-Emotion Stimulus Set,,,,,,,
MultiPic,,http://www.bcbl.eu/databases/multipic/,Picture,,"Du_abeitia, J.A., Crepaldi, D., Meyer, A.S., New, B.,_Pliatsikas, C., Smolka, E., &_Brysbaert, M. (in press)._MultiPic: A standardized set of 750 drawings_with norms for six European languages._Quarterly Journal of Experimental Psychology.",,
,,http://www.face-rec.org/databases/,,,,,
,,https://www.cs.utexas.edu/~chaoyeh/web_action_data/dataset_list.html,ListOfLists,,,,
,,http://imaging.mrc-cbu.cam.ac.uk/methods/stimdatabases,ListOfLists,,,,
,,http://www.psychwiki.com/wiki/Archives_of_data_and_stimuli,ListOfLists,,,,
,,https://github.com/smathot/stimulus-sets/blob/master/stimulus-sets.md,ListOfLists,,,,
,,https://sites.temple.edu/cnltu/useful-links/stimuli/,ListOfLists,,,,
Clifton & Frazier 1996,,,Sentence,,,,Has a lot of syntactic ambiguity stimuli!
Wordnet,,,,,,,
Verbnet,,,,,,,
PropBank,,,,,,,
NOUN database,,http://www.sussex.ac.uk/wordlab/noun,,,,yes!,
SimVerb,,http://people.ds.cam.ac.uk/dsg40/simverb.html,,,,,"Similarity norms, wow! Link it to my whole deal"
Imagact,,_https://www.cs.colorado.edu/~mozer/Teaching/syllabi/TopicsInCognitiveScienceFall2014/IMAGACT-LREC14.pdf,,,,,invented action stimuli??
ARC Nonword database,,http://www.maccs.mq.edu.au/~nwdb/,,,,,Australian novel words